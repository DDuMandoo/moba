import pandas as pd
import numpy as np
import os
from surprise import Dataset, Reader, KNNBasic, accuracy
from surprise.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity

# ---------------------- 1. ë°ì´í„° ë¡œë”© ----------------------
base_dir = os.path.dirname(__file__)
dummy_data = os.path.join(base_dir, "../transaction/transaction_dataset/dummy_receipts.csv")
df = pd.read_csv(dummy_data, encoding="utf-8-sig")

# ìœ ì €-ì†Œë¶„ë¥˜ ê¸°ì¤€ ì˜ìˆ˜ì¦ ê°œìˆ˜
df_grouped = df.groupby(["ì‚¬ìš©ìID", "ì†Œë¶„ë¥˜"]).size().reset_index(name="íšŸìˆ˜")

# ---------------------- 2. Surprise Dataset ìƒì„± ----------------------
reader = Reader(rating_scale=(df_grouped["íšŸìˆ˜"].min(), df_grouped["íšŸìˆ˜"].max()))
data = Dataset.load_from_df(df_grouped[["ì‚¬ìš©ìID", "ì†Œë¶„ë¥˜", "íšŸìˆ˜"]], reader)
trainset, testset = train_test_split(data, test_size=0.25, random_state=42)

# ---------------------- 3. í˜‘ì—… í•„í„°ë§ ëª¨ë¸ í•™ìŠµ ----------------------
sim_options = {
    "name": "cosine",
    "user_based": False
}
model = KNNBasic(sim_options=sim_options)
model.fit(trainset)

# í˜‘ì—… í•„í„°ë§ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
predictions = model.test(testset)
cf_dict = {(pred.uid, pred.iid): pred.est for pred in predictions}

# ---------------------- 4. ì»¨í…ì¸  ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° ----------------------
pivot = df.pivot_table(index="ì‚¬ìš©ìID", columns="ì†Œë¶„ë¥˜", values="ê¸ˆì•¡", aggfunc="mean", fill_value=0)
item_sim_df = pd.DataFrame(
    cosine_similarity(pivot.T),
    index=pivot.columns,
    columns=pivot.columns
)

# ---------------------- 5. alpha ë³„ ì„±ëŠ¥ ì¸¡ì • ----------------------
def evaluate_alpha(alpha):
    hybrid_errors = []
    for pred in predictions:
        user_id, item_id = pred.uid, pred.iid
        cf_score = pred.est

        # ì»¨í…ì¸  ê¸°ë°˜ ì ìˆ˜
        user_items = df_grouped[df_grouped["ì‚¬ìš©ìID"] == int(user_id)]["ì†Œë¶„ë¥˜"].tolist()
        sims = [
            item_sim_df.loc[item_id, used_item]
            for used_item in user_items
            if used_item in item_sim_df.columns and item_id in item_sim_df.index
        ]
        cb_score = np.mean(sims) if sims else 0

        hybrid_score = alpha * cf_score + (1 - alpha) * cb_score
        hybrid_errors.append(abs(hybrid_score - pred.r_ui))  # ì‹¤ì œ ratingê³¼ì˜ ì°¨ì´

    return np.mean(hybrid_errors)

# alpha = 0.0 ~ 1.0 ê¹Œì§€ ì‹¤í—˜
alphas = np.arange(0.0, 1.05, 0.1)
results = {round(a, 2): evaluate_alpha(a) for a in alphas}

best_alpha = min(results, key=results.get)
print("âœ… alphaë³„ í‰ê·  ì˜¤ì°¨:")
for a, score in results.items():
    print(f"alpha = {a:.2f} â†’ í‰ê·  MAE ìœ ì‚¬ë„ ì°¨ì´: {score:.4f}")

print(f"\nğŸ”¥ ìµœì  alpha: {best_alpha:.2f} (ì˜¤ì°¨: {results[best_alpha]:.4f})") # alpha = 0.6, mae=0.9181
